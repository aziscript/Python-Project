{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35aebf2e-0635-4fef-bc9a-877b6a20fb13",
   "metadata": {},
   "source": [
    "![Credit card being held in hand](credit_card.jpg)\n",
    "\n",
    "Commercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n",
    "\n",
    "### The Data\n",
    "\n",
    "The data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e86b1e8-a3fa-4b09-982f-795f218bd1a6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1898,
    "lastExecutedAt": 1713963817980,
    "lastExecutedByKernel": "4ee93555-5ef3-4306-9940-0d4b1932ee53",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \ncc_apps.head()",
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {},
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>g</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>g</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>g</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>g</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>s</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11   12 13\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  g    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  g  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  g  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  g    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  s    0  +"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \n",
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334acf65-caaa-4363-959b-7fd7a6cbc648",
   "metadata": {},
   "source": [
    "### Objective\n",
    "Use supervised learning techniques to automate the credit card approval process for banks.\n",
    "\n",
    "* Preproccess the data and apply supervised learning techniques to find the best model and parameters for the job. Save the accuracy score from your best model as a numeric variable, `best_score`. Aim for an accuracy score of at least `0.75`. The target variable is the last column of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4239b1ea-ea68-470e-8239-2cf2cb43e5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 14 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    int64  \n",
      " 13  13      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 75.6+ KB\n"
     ]
    }
   ],
   "source": [
    "cc_apps.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e53befe-1034-4efd-9f97-b114d8f581c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5afeca54-c989-42b3-bd02-0f92149a7225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ffa0b4-4802-4e1a-aef9-f9eb6436ef93",
   "metadata": {},
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6cc16bb-de76-482e-9cdf-265ccc92332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the '?'s with NaN in dataset\n",
    "cc_apps_nans_replaced = cc_apps.replace(\"?\", np.NaN)\n",
    "\n",
    "# Create a copy of the NaN replacement DataFrame\n",
    "cc_apps_imputed = cc_apps_nans_replaced.copy()\n",
    "\n",
    "# Iterate over each column of cc_apps_nans_replaced and impute the most frequent value \n",
    "# for object data types and the mean for numeric data types\n",
    "for col in cc_apps_imputed.columns:\n",
    "    # Check if the column is of object type\n",
    "    if cc_apps_imputed[col].dtypes == \"object\":\n",
    "        # Impute with the most frequent value\n",
    "        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(\n",
    "            cc_apps_imputed[col].value_counts().index[0]\n",
    "        )\n",
    "    else:\n",
    "        cc_apps_imputed[col] = cc_apps_imputed[col].fillna(cc_apps_imputed[col].mean())\n",
    "\n",
    "# Dummify the categorical features\n",
    "cc_apps_encoded = pd.get_dummies(cc_apps_imputed, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b4f78-188d-42a7-94de-0c000cb803a7",
   "metadata": {},
   "source": [
    "### Prepare the data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4bbddba-ef8e-42d4-9d7d-d60c922a4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last column as your target variable\n",
    "X = cc_apps_encoded.iloc[:, :-1].values\n",
    "y = cc_apps_encoded.iloc[:, [-1]].values\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba24738-e596-4994-995e-0a55fe1e38b9",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c18dff7-3856-44ef-bf98-0a32b69c1818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[203   1]\n",
      " [  1 257]]\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Instantiate StandardScaler and use it to rescale X_train and X_test\n",
    "scaler = StandardScaler()\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(rescaledX_train, y_train)\n",
    "\n",
    "# Use logreg to predict instances from the training set\n",
    "y_train_pred = logreg.predict(rescaledX_train)\n",
    "\n",
    "# Print the confusion matrix of the logreg model\n",
    "print(confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e013fbf-0a0e-4a4d-aa4b-34971f3950e8",
   "metadata": {},
   "source": [
    "### Finding the best scoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5ebb6e1-dee3-45d6-b903-092d98913280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.818256 using {'max_iter': 100, 'tol': 0.01}\n",
      "Accuracy of logistic regression classifier:  0.7982456140350878\n"
     ]
    }
   ],
   "source": [
    "# Define the grid of values for tol and max_iter\n",
    "tol = [0.01, 0.001, 0.0001]\n",
    "max_iter = [100, 150, 200]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists of their values are the corresponding values\n",
    "param_grid = dict(tol=tol, max_iter=max_iter)\n",
    "\n",
    "# Instantiate GridSearchCV with the required parameters\n",
    "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit grid_model to the data\n",
    "grid_model_result = grid_model.fit(rescaledX_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "best_train_score, best_train_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_train_score, best_train_params))\n",
    "\n",
    "# Extract the best model and evaluate it on the test set\n",
    "best_model = grid_model_result.best_estimator_\n",
    "best_score =  best_model.score(rescaledX_test, y_test)\n",
    "\n",
    "print(\"Accuracy of logistic regression classifier: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5315e0-5708-44bd-89f1-a8e9e8df95f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
